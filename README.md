# trabajo-ia

En este repositorio están algunos de mis trabajos en el ámbito del Aprendizaje Automático. En ellos hago uso de distintos modelos para hacer predicciones sobre el precio del sector inmobiliario. Para conseguir los mejores resultados posibles he tenido que estudiar bien el DataSet y entender que relaciones había entre cada una de las 21 características, tanto entre ellas como con el precio. Entre otras cosas he tenido que trabajar con la famosas librerías Sklear, Numpy, Pandas etc.

Entre los modelos que he probado para hacer las predicciones están los siguientes:

- Linear Regressor
- Support Vector Machine Regressor (SVM)
- K-Nearest Neighbors Regressor (KNN)
- Regression Trees 
- Random Forest Regressor

Para conseguir los mejores resultados posibles he tenido que trabajar mucho en los siguientes aspectos:
- El estudio de los datos: Para estudiar los datos ha sido indispensable la visualización de ellos, dado que es muy complicado hacerse una idea intuitiva de que está sucediendo cuando tenemos tanta información si no podemos visualizarla. También he mirado las correlaciones siguientes: Correlación de Pearson, Kendall y Spearman.
- El preprocesamiento de datos: Una vez analizados los datos hay que hacer algo con todo ese conocimiento. Entre otras cosas he imputado las medianas, me he encargado de los outlayers haciendo uso de los percentiles y también he hecho uso de los OneHotEncoders (dummies) para poder utilizar las características categóricas. Por otro lado también he hecho uso de la función logaritmo para conseguir correlaciones lineales más fuertes entre los predictores y las predicciones.
- Las pruebas con los modelos: Realmente podemos probar los modelos desde el principio, pero los resultados no serán demasiado buenos si no preparamos los datos para ellos. Lo que vamos a hacer aquí es darle una oportunidad a los modelos de entrenarse y hacer predicciones y ver que resultados están dando. Utilizaremos la función de error RMSE(Root Mean Squared Error), en castellano Raíz del Error Cuadrático Medio. También he hecho uso de método Cross-Validation para tener una información que dependa menos del factor aleatorio y más de la fiabilidad de los modelos.
- La selección de características: Una vez probados los modelos podemos pensar que a lo mejor meter todos los datos no es la mejor opción. Hay muchas columnas que añaden mucha complejidad a los modelos y no mejoran para nada los resultados. Estas columnas no se tienen que utilizar, pero escoger cuales se quedan y cuales no puede ser una árdua tarea. Para automatizar el proceso he montado un sistema de Backward Feature Selection, que nos ayudará a encontrar cuales son las mejores columnas para el modelo.
- La selección de los hyperparámetros: Aún nos queda una cosa más por hacer para extraer todo el jugo de algunos nuestros modelos. En el modelo de Regresión Lineal no tenemos ningún parámetro que ajustar, pero en el resto de modelos hay parámetros que afectan a como trabajan y que resultados consiguen estos modelos. Para ajustarlos he hecho uso primero de todo del sentido común, y segundo de la función GridSearchCV. Esta función permite hacer una búsqueda en el espacio de parámetros que nosotros le pongamos para encontrar la mejor combinación de ellos haciendo uso de la CrossValidation.
- La iteración: Aunque este proceso lo haya definido aquí como algo lineal y ordenado, en realidad he tenido que volver muchas veces hacia atrás para ir ajustando las distintas fases para ir mejorando todo poco a poco. Por poner un ejemplo: aunque en un principio había hecho una pipeline de preprocesamiento de datos que podía ser un biuen comienzo, luego he tenido que ir ajustándola a algunos modelos que no tienen los mismos requisitos que los otros. Claramente la regresión linela depende muchísimo de las correlaciones lineales, mientras que el Random Forest no tiene esos problemas. 
